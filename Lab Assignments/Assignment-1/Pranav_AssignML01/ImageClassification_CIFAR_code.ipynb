{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm \n",
    "import tarfile\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_dataset_folder_path = '/home/pranav/My Data/M.Tech/ML/Lab Assignments/Assignment-1/cifar-10-python/cifar-10-batches-py'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label_names():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Training Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cfar10_batch(cifar10_dataset_folder_path, batch_id):\n",
    "    with open(cifar10_dataset_folder_path + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
    "        # note the encoding type is 'latin1'\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    labels = batch['labels']\n",
    "        \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating 10 lists to classify training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "list0 = []\n",
    "list1 = []\n",
    "list2 = []\n",
    "list3 = []\n",
    "list4 = []\n",
    "list5 = []\n",
    "list6 = []\n",
    "list7 = []\n",
    "list8 = []\n",
    "list9 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Training Data using their respective labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "def trainging_classifier(cifar10_dataset_folder_path):\n",
    "    global list0\n",
    "    global list1\n",
    "    global list2\n",
    "    global list3\n",
    "    global list4\n",
    "    global list5\n",
    "    global list6\n",
    "    global list7\n",
    "    global list8\n",
    "    global list9\n",
    "\n",
    "        \n",
    "    for batch_id in range(1,6):\n",
    "        print(batch_id)#Iterating over all batches\n",
    "        features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_id)\n",
    "        for i in range(len(features)): #Classifying all samples to respective class list\n",
    "            if labels[i] == 0:\n",
    "                list0.append(features[i])\n",
    "            elif labels[i] == 1:\n",
    "                list1.append(features[i])\n",
    "            elif labels[i] == 2:\n",
    "                list2.append(features[i])\n",
    "            elif labels[i] == 3:\n",
    "                list3.append(features[i])\n",
    "            elif labels[i] == 4:\n",
    "                list4.append(features[i])\n",
    "            elif labels[i] == 5:\n",
    "                list5.append(features[i])\n",
    "            elif labels[i] == 6:\n",
    "                list6.append(features[i])\n",
    "            elif labels[i] == 7:\n",
    "                list7.append(features[i])\n",
    "            elif labels[i] == 8:\n",
    "                list8.append(features[i])\n",
    "            elif labels[i] == 9:\n",
    "                list9.append(features[i])\n",
    "    list0 = np.array([np.array(im1) for im1 in list0]) #Converting All image lists to numpy arrarys\n",
    "    list1 = np.array([np.array(im2) for im2 in list1])\n",
    "    list2 = np.array([np.array(im3) for im3 in list2])\n",
    "    list3 = np.array([np.array(im4) for im4 in list3])\n",
    "    list4 = np.array([np.array(im5) for im5 in list4])\n",
    "    list5 = np.array([np.array(im6) for im6 in list5])\n",
    "    list6 = np.array([np.array(im7) for im7 in list6])\n",
    "    list7 = np.array([np.array(im8) for im8 in list7])\n",
    "    list8 = np.array([np.array(im9) for im9 in list8])\n",
    "    list9 = np.array([np.array(im0) for im0 in list9])\n",
    "\n",
    "        \n",
    "    #print(list0.shape[0])\n",
    "    \n",
    "    \n",
    "\n",
    "trainging_classifier(cifar10_dataset_folder_path)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Average Images and saving them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"      \\n    # saving the final output  \\n    # as a PNG file \\nresult0.save('result0.png')\\nresult1.save('result1.png')\\nresult2.save('result2.png')\\nresult3.save('result3.png')\\nresult4.save('result4.png')\\nresult5.save('result5.png')\\nresult6.save('result6.png')\\nresult7.save('result7.png')\\nresult8.save('result8.png')\\nresult9.save('result9.png')\\n\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                                #Find arrays of all lists\n",
    "avg0 = np.average(list0,axis=0) \n",
    "avg1 = np.average(list1,axis=0)\n",
    "avg2 = np.average(list2,axis=0)\n",
    "avg3 = np.average(list3,axis=0)\n",
    "avg4 = np.average(list4,axis=0)\n",
    "avg5 = np.average(list5,axis=0)\n",
    "avg6 = np.average(list6,axis=0)\n",
    "avg7 = np.average(list7,axis=0)\n",
    "avg8 = np.average(list8,axis=0)\n",
    "avg9 = np.average(list9,axis=0)\n",
    "\n",
    "\n",
    "                                #Converting average array back to images\n",
    "#print(avg0.shape)\n",
    "result0 = Image.fromarray(avg0.astype('uint8'))\n",
    "result1 = Image.fromarray(avg1.astype('uint8'))\n",
    "result2 = Image.fromarray(avg2.astype('uint8'))\n",
    "result3 = Image.fromarray(avg3.astype('uint8'))\n",
    "result4 = Image.fromarray(avg4.astype('uint8'))\n",
    "result5 = Image.fromarray(avg5.astype('uint8'))\n",
    "result6 = Image.fromarray(avg6.astype('uint8'))\n",
    "result7 = Image.fromarray(avg7.astype('uint8'))\n",
    "result8 = Image.fromarray(avg8.astype('uint8'))\n",
    "result9 = Image.fromarray(avg9.astype('uint8'))\n",
    "\n",
    "#print(result2.shape)\n",
    "\n",
    "#plt.imshow(result)\n",
    "\n",
    "                             #Commented it as all images have aready been saved\n",
    "\"\"\"      \n",
    "    # saving the final output  \n",
    "    # as a PNG file \n",
    "result0.save('result0.png')\n",
    "result1.save('result1.png')\n",
    "result2.save('result2.png')\n",
    "result3.save('result3.png')\n",
    "result4.save('result4.png')\n",
    "result5.save('result5.png')\n",
    "result6.save('result6.png')\n",
    "result7.save('result7.png')\n",
    "result8.save('result8.png')\n",
    "result9.save('result9.png')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Test Batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_batch(cifar10_dataset_folder_path):\n",
    "    with open(cifar10_dataset_folder_path + '/test_batch' , mode='rb') as file:\n",
    "        # note the encoding type is 'latin1'\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "    test_samples = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    test_labels = batch['labels']\n",
    "        \n",
    "    return test_samples, test_labels\n",
    "\n",
    "test_samples, test_labels = load_test_batch(cifar10_dataset_folder_path)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Average List (List of lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_list = list()\n",
    "avg_list.append(result0)\n",
    "avg_list.append(result1)\n",
    "avg_list.append(result2)\n",
    "avg_list.append(result3)\n",
    "avg_list.append(result4)\n",
    "avg_list.append(result5)\n",
    "avg_list.append(result6)\n",
    "avg_list.append(result7)\n",
    "avg_list.append(result8)\n",
    "avg_list.append(result9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a distance matrix\n",
    "Computing the Eucledian distance b/w 2 images and returning the distance list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_matrix():\n",
    "    row = list()\n",
    "    distance_matrix = list()\n",
    "    #plt.imshow(avg_list[0])\n",
    "    #print(len(test_samples))\n",
    "    for i in range(len(test_samples)):\n",
    "        col = [0]*len(avg_list)\n",
    "        for j in range(len(avg_list)):\n",
    "            col[j] = np.linalg.norm(test_samples[i]-avg_list[j])   #Eucledian distance b/w 2 images\n",
    "        distance_matrix.append(col)\n",
    "         \n",
    "    #rint(distance_matrix.sha)\n",
    "    return distance_matrix\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the least distance among all class labels for each test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindLeastDistance():\n",
    "    distance_matrix = avg_matrix()\n",
    "    prediction = list()\n",
    "    \n",
    "    for i in range(len(distance_matrix)): #Iterating over the rows\n",
    "        min1 = float('inf')\n",
    "        for j in range(len(distance_matrix[0])): #Iterating over the cols\n",
    "            if (distance_matrix[i][j] < min1 ):\n",
    "                min1 = distance_matrix[i][j]\n",
    "        prediction.append(distance_matrix[i].index(min1))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Accuracy and Error of Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data Error % =  88.72\n"
     ]
    }
   ],
   "source": [
    "prediction = FindLeastDistance()\n",
    "score =0\n",
    "for i in range(len(test_labels)):\n",
    "    if(test_labels[i]==prediction[i]):\n",
    "        score +=1                         #Computes the score of the classifer\n",
    "accuracy = score/len(test_labels)\n",
    "error = 1 - accuracy\n",
    "print(\"Test data Error % = \", error*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[251 138  48  23  53  32 196  52  98 109]\n",
      " [275  38   5  19  44  62 232  39 111 175]\n",
      " [226  63  20   8  46  21 373  33  81 129]\n",
      " [240  56   5   8  25  54 298  29  92 193]\n",
      " [156  48   6   9  16  15 424  17 122 187]\n",
      " [231  45   5  13  13  71 311  22 124 165]\n",
      " [253  31   2   6  17  17 381  18  88 187]\n",
      " [162  60   7  10  24  25 288  16 185 223]\n",
      " [123  92  11  27  83  36 230  69 147 182]\n",
      " [237  51   9  20  46  61 213  72 111 180]]\n"
     ]
    }
   ],
   "source": [
    "confusion_array = confusion_matrix(test_labels, prediction)\n",
    "print(confusion_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Confusion Matrix to an Excel Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "workbook = xlsxwriter.Workbook('Confusion_Matrix.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "row = 0\n",
    "temp = np.transpose(confusion_array) \n",
    "for col, data in enumerate(temp):\n",
    "    worksheet.write_column(row, col, data)\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef avg_matrix():\\n    #global test_samples\\n    #global avg_list\\n    distance_matrix = [[0] *10]* len(test_samples)\\n    #plt.imshow(avg_list[0])\\n    #print(len(test_samples))\\n    for i in range(len(test_samples)):\\n        #j=0\\n        for j in range(len(avg_list)):\\n            #print(i,j)\\n            distance_matrix[i][j] = np.linalg.norm(test_samples[i]-avg_list[j])\\n        \\n            \\n    #rint(distance_matrix.sha)\\n    return distance_matrix\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unused Code : Ignore\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def display_stats(cifar10_dataset_folder_path, batch_id, sample_id):\n",
    "    features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_id)\n",
    "    \n",
    "    if not (0 <= sample_id < len(features)):\n",
    "        print('{} samples in batch {}.  {} is out of range.'.format(len(features), batch_id, sample_id))\n",
    "        return None\n",
    "\n",
    "    print('\\nStats of batch #{}:'.format(batch_id))\n",
    "    print('# of Samples: {}\\n'.format(len(features)))\n",
    "    \n",
    "    label_names = load_label_names()\n",
    "    label_counts = dict(zip(*np.unique(labels, return_counts=True)))\n",
    "    for key, value in label_counts.items():\n",
    "        print('Label Counts of [{}]({}) : {}'.format(key, label_names[key].upper(), value))\n",
    "    \n",
    "    sample_image = features[sample_id]\n",
    "    sample_label = labels[sample_id]\n",
    "    \n",
    "    \n",
    "    #ims = []\n",
    "    #ims.append(sample_image)\n",
    "    \n",
    "    \n",
    "    print('\\nExample of Image {}:'.format(sample_id))\n",
    "    print('Image - Min Value: {} Max Value: {}'.format(sample_image.min(), sample_image.max()))\n",
    "    print('Image - Shape: {}'.format(sample_image.shape))\n",
    "    print('Label - Label Id: {} Name: {}'.format(sample_label, label_names[sample_label]))\n",
    "    \n",
    "    plt.imshow(sample_image)\n",
    "\"\"\"   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def avg_matrix():\n",
    "    #global test_samples\n",
    "    #global avg_list\n",
    "    distance_matrix = [[0] *10]* len(test_samples)\n",
    "    #plt.imshow(avg_list[0])\n",
    "    #print(len(test_samples))\n",
    "    for i in range(len(test_samples)):\n",
    "        #j=0\n",
    "        for j in range(len(avg_list)):\n",
    "            #print(i,j)\n",
    "            distance_matrix[i][j] = np.linalg.norm(test_samples[i]-avg_list[j])\n",
    "        \n",
    "            \n",
    "    #rint(distance_matrix.sha)\n",
    "    return distance_matrix\n",
    "\"\"\"            \n",
    "        \n",
    "#distance_matrix2 = avg_matrix()\n",
    "#print(avg_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
